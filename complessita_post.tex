% !TeX spellcheck = it_IT
\documentclass[a4paper, headings=standardclasses]{scrartcl}

\usepackage[margin=2.5cm]{geometry}
\usepackage{authblk}
\renewcommand{\Affilfont}{\small}
\usepackage[style=apa, backend=biber, sorting=ynt, sortcites=true, useprefix=true]{biblatex}
\usepackage[autostyle=false, style=english]{csquotes}
\MakeOuterQuote{"}
\usepackage[italian]{babel}
\usepackage[modulo]{lineno}
\linenumbers
\usepackage[hidelinks]{hyperref}

\usepackage{textcomp}

\addbibresource{complexity.bib}

%opening
\title{Sulla complessità come meta-teoria\let\thefootnote\relax\footnotetext{
		Versioni precedenti di questo lavoro sono state presentate alla 24esima ESHET Summer School e alla 2023 INEM Conference. \\
		L'ultima versione di questo lavoro è disponibile online \url{https://github.com/TnTo/complexity-economics/}.
}}
\subtitle{una discussione dalla prospettiva dell'economia}
\author{Margherita Redigonda\thanks{mciruzzi@uninsubria.it - \url{https://orcid.org/0000-0003-1485-1204}}}

\begin{document}
	
	\maketitle
	
	\begin{abstract}
		... \\
		\textbf{Keywords:} Complessità, Meta-Teoria, Riduzionismo\\
		\textbf{JEL Codes: B41, B59, A14}
	\end{abstract}
	
\section{Sulla Complessità}
Trattare il tema della complessità è generalmente qualcosa di molto difficile da fare per la natura ambigua e sfuggente del termine.
Innanzitutto, complessità è ormai diventata una \textit{buzzword} spesso priva di significato proprio.
Inoltre non esiste una definizione condivisa di cosa sia la complessità a livello scientifico\footnote{\textcite{horgan2015}, citato in \textcite{holt2011}, elenca 45 differenti idee da cui partire per cercare una definizione di complessità.} rendendo difficile trattare con precisione l'argomento.

La causa di ciò credo divenga evidente una volta che si guarda il problema della definizione di complessità da una prospettiva storica. 

Una lista di ciò che oggi è senza dubbio oggetto di studio da parte della teoria della complessità non può non contenere, tra le altre cose, i sistemi dinamici (in particolare il caos deterministico e la teoria delle biforcazioni) e la meccanica statistica. Per entrambe le discipline di studio è possibile ricondurne la nascita (o almeno un momento fondativo) agli anni 1870, quando Poincaré pubblicò i primi lavori sulle ricorrenze e Boltzmann presentò i primi risultati su cui fondare la meccanica statistica.

D'altra parte, il termine complessità entra nel lessico scientifico con l'articolo di \citeauthor{anderson1972} del \citeyear{anderson1972} \citetitle{anderson1972}, che si apre mettendo in discussione il paradigma riduzionista su cui si basa la scienza moderna, riconoscendo che sebbene si possa creare una gerarchia di scienze secondo la visione riduzionista (ad esempio fisica \textrightarrow{} chimica \textrightarrow{} biologia \textrightarrow{} fisiologia \textrightarrow{} psicologia \textrightarrow{} sociologia) non è sostenibile affermare che "X è semplicemente Y applicata".
Ovvero che non è possibile riformulare sulla base delle leggi della disciplina più ridotta tutte le leggi della disciplina più complessa (cioè non possiamo esprimere, ad esempio, tutta la conoscenza psicologica facendo riferimento solo ai fenomeni fiosiologici sottostanti).

Nel momento in cui Anderson pubblica il suo articolo, però, sono già stati sviluppati numerosi metodi matematici per gestire i "sistemi complessi" e si è già diffuso un \textit{senso comune} su quali problemi siano oggetto di studio da parte della teoria della complessità (come citato prima i sistemi dinamici e la termodinamica, a cui possiamo aggiungere, senza pretesa di esaustività, la teoria dell'informazione, i processi stocastici, i modelli computazionali ad agenti, la teoria dei giochi, la teoria dei grafi o delle reti).
In altre parole, nel momento in cui compare una definizione e un tentativo di fondare metodologicamente il campo di ricerca, lo sviluppo delle tecniche matematiche per indagarlo è già avanzato e si è sviluppato in una prospettiva indipendente e riduzionista.

Compare qui una tensione che è probabilmente il punto focale dell'articolo: seguendo Anderson la complessità non può che essere anti-riduzionista ma i metodi matematici della teoria della complessità nascono e si sviluppano in una prospettiva riduzionista.

Torniamo alla meccanica statistica come esempio archetipico. Il problema che essa risolve è di ricondurre un fenomeno macroscopico (le leggi della termodinamica e l'irreversibilità dei processi fisici) alle leggi microscopiche note (la dinamica molecolare) come prescritto dal paradigma riduzionista.  Ciò elimina la necessità di avere due differenti teorie per il microscopico e il macroscopico, riconducendo i fenomeni macroscopici a manifestazioni di leggi microscopiche.

Questo in teoria. Nella pratica, però, le leggi macroscopiche rimangono correntemente in uso per ragioni di semplicità e adeguatezza, perché descrivono meglio la realtà macroscopica e restituiscono rappresentazioni più semplici da usare e che sono comunque sufficientemente accurate.
Inoltre, la meccanica statistica ha creato una nuova descrizione mesoscopica dove le leggi microscopiche e macroscopiche si mischiano descrivendo fenomeni che non possono essere spiegati né solo dalle une né solo dalle altre, richiedendo di fatto un apparato teorico nuovo di leggi mesoscopiche.

In questo senso possiamo recuperare l'intuizione di Anderson: nel momento in cui si prova a ridurre il macroscopico al microscopico si perde in accuratezza nella descrizione del macroscopico (o almeno di praticità) mentre si esplora un'area grigia che non appartiene né al macroscopico né al microscopico e, al contempo, appartiene a entrambi.
Si ottiene quindi una nuova formulazione che è nella pratica inutilizzabile e inadeguata a essere usata come teoria scientifica per uno dei due livelli e, potenzialmente, si mette in luce un livello intermedio terzo che ha bisogno di un proprio e distinto apparato di leggi.

Per procedere oltre nella discussione è probabilmente necessario quantomeno avvicinarsi a una definizione dell'oggetto di studio: la complessità.

I concetti che più spesso vengono associati a quest'idea sono la relazione tra le parti e il tutto, la differenza tra comportamenti individuali e collettivi, le proprietà emergenti, le relazioni tra le parti, la non-linearità\footnote{La non-linearità potrebbe sembrare la carta spaiata nell'elenco, ma la sua relazione con le altre idee è semplice da mostrare. Ipotizziamo un insieme di elementi $\{x_i\}$ e supponiamo di aggregarli sommandoli come $X=\sum_i x_i$. La relazione tra il cambiamento di uno degli elementi dell'insieme e il cambiamento dell'aggregato è $\Delta X=\Delta x_i$, identificando tra loro i cambiamenti macro e microscopici ed eliminando la necessità di due rappresentazioni diverse della dinamica. Un caso forse più comune e analogo in economia è quello della log-linearità quando la funzione di aggregazione è il prodotto, ovvero $X = \log(\prod_i x_i)$ e $\Delta X=\Delta\log(x_i)$.}. Per questo motivo è comune parlare di \textit{sistemi complessi} quasi come sinonimo di complessità, perché la parola sistema sottende non molto più che un insieme di parti in relazione tra loro.

La definizione di complessità che propongo è la seguente:
\begin{quote}
	Un sistema è complesso se deve essere descritto differentemente su diversi livelli di una o più scale.
\end{quote}

Per assumere di senso, questa definizione, richiede di definire cosa siano una scala e i suoi livelli. Ma prima di fare ciò spenderò due parole sull'idea di descrizione.

Ogni teoria scientifica mira alla comprensione del reale attraverso una sua rappresentazione semplificata che permetta di metterne a fuoco particolari caratteristiche d'interesse. Queste rappresentazioni sono generalmente prodotte nella forma di leggi o modelli.
Al contempo però, ciascuna di queste rappresentazioni esprime solo una particolare descrizione del reale che si concentra su alcuni dettagli tralasciandone altri\footnote{Si potrebbe, come esperimento mentale, pensare di riuscire a creare una descrizione del reale così comprensiva e precisa, al contempo analitica e sintetica, da rendere ogni altra obsoleta, ma non si discosterebbe molto da una mappa 1:1 del mondo, sulla cui inutilità e impraticità hanno scritto, meglio di me, Eco e Borges.}.

Questa osservazione ci consegna una prima intuizione su cosa sia la complessità: riconoscere che il mondo è composto da troppi enti, legati tra loro da troppi nessi e relazioni, per poterne isolare uno alla volta o studiarli tutti insieme con precisione. Invece, è necessario riconoscere, di volta in volta, quali siano i dettagli importanti massi a fuoco, l'ingrandimento necessario per vedere ciò che interessa, consapevoli però di cosa e perché sia rimasto fuori dal campo visivo.

Seguendo questa metafora provo a spiegare cosa intendo per scala e livelli.

Pensiamo a un vetrino per il microscopio con un singolo campione. Questo campione appare
in maniera molto diversa a seconda dell'ingrandimento o del piano focale scelti per l'osservazione.
Queste due variabili, due dimensioni lungo cui muoversi, cambiano il nostro modo di osservare il campione e la descrizione che ne possiamo dare.
La percezione che abbiamo del campione e quindi le caratteristiche e le proprietà che possiamo
descrivere, variano al variare delle due variabili (l'ingrandimento e il piano focale) di osservazione.

Abbiamo cioè introdotto due dimensioni, che chiamiamo scale, che presentano differenti modi, i livelli, di osservare, o descrivere, uno stesso ente.

Esempi tipici di scale sono la scala geografica (che in riferimento al sistema economico ha come livelli, ad esempio, una città, un distretto industriale, una nazione, un continente, l'intero
mercato globale) oppure la scala temporale (tra i cui livelli possiamo elencare il breve periodo, usato ad esempio per i modelli a capitale fisso, e il lungo periodo).

Un'altra scala, forse meno intuitive, che trova enorme spazio nella descrizione dei fenomeni economici è la scala di aggregazione, tra i cui livelli troviamo l'individuo (micro), i gruppi (meso) e l'intera società (macro), che ci permette di descrivere come i concetti di molteplicità e relazione influenzano la descrizione del sistema economico, e quindi di descrivere quei comportamenti dell'individuo che trovano spiegazione solo nella sua relazione con altri. 

Altre dimensioni lungo le quali varia la descrizione, e che quindi qui chiamo scale, sono meno intuitivamente delle scale.
Ad esempio possiamo interpretare la prospettiva di genere come una scala.
Uno stesso fenomeno può essere studiato ignorando il genere dei soggetti coinvolti, utilizzando una prospettiva binaria basandosi sul sesso biologico dei soggetti coinvolti, mantenendo una prospettiva comunque binaria ma basata sul genere e sulla socializzazione dei soggetti coinvolti, o adottando una prospettiva queer includendo una molteplicità di categorie di classificazione basate sull'autorappresentazione dei soggetti coinvolti.
Ognuno di questi livelli restituisce all'osservatore differenti caratteristiche del sistema studiato e nessuno di questi è a priori quello corretto.
Uno progetto di ricerca in medicina sulla salute riproduttiva probabilmente utilizzerà una prospettiva basata sul sesso biologico che è, almeno in prima approssimazione, un fattore determinante, senza introdurre però una ricchezza maggiore di dettagli che risulterebbero solamente rumore all'atto dell'analisi statistica dei risultati\footnote{Almeno in prima approssimazione. Ottenuti i risultati dello studio iniziale potrebbe risultare estremamente utile cambiare livello di osservazione sulla scala per poter descrivere, ad esempio, gli stessi fenomeni nella popolazione sottoposta a terapia ormonale sostitutiva a seguito di una diagnosi di incongruenza di genere.}.
Allo stesso modo, un'etnografia sui movimenti queer difficilmente potrà rinunciare al livello di dettaglio ed eterogeneità che risiede nell'autorappresentazione dei singoli.

Riassumendo, una scala è un aspetto del sistema, una sua area semantica o concettuale, che possa essere analizzato da punti di vista diversi o con differenti livelli di dettaglio.
E un sistema complesso è qualunque sistema che cambi le proprie caratteristiche, o meglio la descrizione che se ne si può fare, a seconda del punto di osservazione. In altre parole, un sistema che non si mantenga sempre uguale a se stesso e coerente sotto ogni punto di vista.

È probabile che seguendo questa definizione la realtà sia complessa e sia complesso anche quasi ogni suo sottoinsieme. Ma non vedo problematicità in ciò.

Quello che fa, invece, questa definizione, oltre a includere --credo-- tutte le differenti intuizioni sulla natura della complessità grazie all'astrattezza e alla generalezza dell'idea di scala, è porre indirettamente l'attenzione sulle approssimazioni che esplicitamente o (più spesso) implicitamente vengono fatte in ogni ricerca scientifica e in ogni descrizione del reale.

Quello che non fa questa definizione è fornire direttamente un qualche tipo di conoscenza specifica in qualsivoglia ambito del sapere.
In questo senso non possiamo considerare la teoria della complessità, per come è appena stata definita, una teoria in senso stretto.

Piuttosto essa fornisce delle indicazioni su come operazionalizzare l'osservazione, e quindi lo studio, di un sistema complesso, ovvero su come costruire delle teorie sui diversi sistemi complessi.

In questo senso credo sia più corretto parlare di una meta-teoria della complessità, ovvero di una teoria su come sia necessario sviluppare le teorie che descrivono i sistemi complessi\footnote{Se è vero quanto accennato prima sull'essere la realtà stessa un sistema complesso in ogni suo aspetto, allora la meta-teoria della complessità fornisce dei principi di cui deve tenere conto ogni teoria scientifica.}.

Si potrebbe argomentare che il caso particolare della fisica sia sufficiente ad abbattere la costruzione argomentativa che sto portando avanti, fornendo un fortissimo argomento a favore del mantenimento di un paradigma riduzionistico.
Attraverso passaggi logici è possibile a oggi ricondurre quasi ogni legge fisica a un piccolo numero di forze fondamentali (tra una e tre a seconda delle teorie), che sono in grado quindi di spiegare ogni fenomeno del reale.

Da un punto di vista speculativo, assumendo per semplicità una realtà assolutamente deterministica, questo potrebbe sembrare effettivamente la realizzazione del sogno riduzionista di ricondurre ogni fenomeno a una manciata di principi primi e quindi alla possibilità di formulare una \textit{legge del tutto} che governa la realtà in ogni suo aspetto. Ma tale pensiero non trova riscontro pratico o esperienziale.
Nessun ricercatore proverebbe mai a descrivere nemmeno la statica di un ponte usando le poche leggi fondamentali, per non dire di fenomeni più complessi nel regno animale o nella sfera culturale.
E come già detto, anche nella stessa fisica esistono fenomeni che sono ricondotti alla teoria unificante solo in condizioni ideali e perfette, le cui imprecisioni reali sono meglio spiegate da teorie e correzioni ad hoc, sviluppate per il caso specifico senza pretese di universalità.

L'anti-riduzionismo presente nel lavoro di Anderson e nell'idea di una meta-teoria della complessità può essere quindi riformulato come il rifiuto della possibilità di una teoria del tutto e di un punto di vista privilegiato.

Come conseguenza, la conoscenza non può che essere intesa come contestuale e funzionale, ovvero legata a particolari premesse e scopi che evidenziano caratteristiche diverse dello stesso oggetto di studio, determinando approssimazioni diverse che evidenziano diversi livelli su diverse scale.

Fare ricerca secondo questa accezione di complessità richiede quindi di rimettere al centro la specifica domanda di ricerca, o di riconoscere la specifica sfaccettatura del reale da osservare, e assumerla come punto di partenza.
Da lì è necessario descrivere nel modo più preciso e ricco possibile l'oggetto di studio per poter riconoscere quante più scale rilevanti possibili e su ognuna di essi i livelli più adatti allo scopo, ovvero di esplicitare con la maggiore precisione possibile le proprie premesse, per poi approssimare l'oggetto di studio a una sua rappresentazione --a un suo modello-- che sia gestibile e affrontabile.

L'atto, qui così centrale, di descrivere richiede un'analisi accurata, senza, almeno in primo luogo, scorciatoie e approssimazioni. In alcuni contesti è possibile che ciò possa essere fatto con cura e minuzia usando il linguaggio formale della matematica o una lingua che non si padroneggia perfettamente, ma in generale se descrivere (e quindi, forse, comprendere intimamente) diventa un aspetto fondamentale della pratica scientifica, il ritorno all'uso del proprio linguaggio naturale (e forse anche l'uso della multi-medialità) diventa una pratica imprescindibile\footnote{Questa è solo una delle difficoltà pratiche che l'adozione della meta-teoria della complessità deve affrontare nella ricerca contemporanea. L'ultima sezione di questo articolo cerca di approfondire maggiormente la questione.}.

Così delineata, la meta-teoria della complessità si avvicina una metodologia del particolare e dell'unico, che riconosce che i tratti importanti di un sistema sono molteplici e differenti a seconda dello scopo, della storia e della soggettività di chi porta avanti la ricerca. Riconosce, in una certa misura, il ruolo organico del particolare all'interno del generale, piuttosto che assumere il particolare come variazione sul tema del generale. 

Il protagonismo del particolare richiede di estendere i metodi a disposizione del ricercatore, e in particolare di recuperare i metodi qualitativi anche dove il loro uso si è perso. Questo perché l'uso complementare di metodi qualitativi e quantitativi è in grado di esplorare lo stesso fenomeno a un maggior numero livelli diversi, per ottenerne una conoscenza più ricca e sfaccettata.

Allo stesso modo, l'esperienza umana individuale viene riconosciuta come portatrice una dimensione propria, quantomeno come determinante della descrizione che il ricercatore fa, osservabile dal giusto livello della giusta scala, e non come mera variazione di un archetipo generale. 
In questo senso, penso si possa riconoscere che la complessità così intesa offra una cornice concettuale per quelle istanze che cercano di portare una prospettiva intersezionale, democratica e di cura all'interno della pratica scientifica.

Per chiudere la sezione mi soffermo su un dibattito vivo in molte discipline, tra cui l'economia, sulla coesistenza di teorie alternative e il problema di scegliere una teoria rispetto. Il dibattito sul pluralismo. 

Col termine pluralismo si indica di solito una visione per cui all'interno di una disciplina possano (o debbano) coesistere una pluralità di teorie diverse tra loro alternative e, generalmente, inconciliabili. 
È il caso anche in fisica in cui teorie diverse per la fisica delle alte energie competono per essere riconosciute come la teoria "giusta", cioè in accordo con tutte le evidenze sperimentali.

L'idea di pluralismo richiede l'esistenza di una teoria corretta, di una teoria del tutto che possa dimostrare sbagliate le teorie alternative.

In un approccio che invece riconosce ogni teoria come necessariamente contestuale, ovvero con dei limiti al proprio dominio di applicazione (intesi come gli intervalli su alcune scale per cui è stata sviluppata) l'idea di pluralismo perde di senso, in quanto la convivenza di teorie con scopi e premesse differenti è una caratteristica intrinseca.

La meta-teoria della complessità ci suggerisce che la fisica newtoniana, l'elettromagnetismo classico e persino il geocentrismo non siano teorie sbagliate, ma sono teorie e modelli che (come tutti) hanno un campo di validità non universale, ma che nel loro campo di validità sono utili perché rispondono alle domande per cui sono state creati, perché rispondono a uno scopo.

Un esempio dall'economia può essere invece lo studio dei fenomeni di lungo periodo.
Esistono almeno quattro approcci diversi nella storia dell'economia di descrivere il lungo periodo: l'approccio neoclassico, che descrive l'esistenza di un unico equilibrio di lungo periodo e il comportamento del sistema economico che rilassa verso di esso; l'approccio post-keynesiano, che descrive la possibilità di stati stazionari multipli, simili nell'idea a equilibri instabili, fra cui il sistema economico può muoversi; l'approccio marxiano, che descrive qualitativamente alcune caratteristiche della dinamica del sistema economico nel lungo periodo, senza descrivere però il punto di arrivo di essa con precisione sufficiente a essere studiato; l'approccio che fa propria la teoria del caos deterministico, che descrivendo l'economia come un sistema caotico conclude l'impossibilità di studiarne il comportamento di lungo periodo, per il progressivo accumularsi di errori inevitabili in qualunque rappresentazione.
Ciascuno di questi quattro approcci permette di studiare aspetti diversi del futuro, rispondendo a domande diverse.

Non vedo dei motivi validi per preferire un paradigma scientifico che cerchi di riconoscere quale di questi sia la corretta rappresentazione della realtà in ogni situazione, invece che ragionare sulle ipotesi implicite e esplicite dietro ad ognuno di essi\footnote{Per esempio un'assunzione troppo spesso dimenticata del modello neoclassico è quella di tempo normale, o di assenza di shock esogeni. Trovo più interessante discutere di cosa renda un tempo \textit{normale} e quindi in quali condizioni la rappresentazione neoclassica sia utile, che inscenare una gara su chi abbia ragione \textit{in assoluto}.}.

Piuttosto che una visione pluralistica di sviluppo della conoscenza, la meta-teoria della complessità fa propria una visione laica, in cui lo sviluppo di ogni teoria è un tassello utile se non necessario per completare il quadro generale e in cui ogni teoria ha di per sé diritto a esistere nel suo dominio di applicazione.

Allo scontro intellettuale si sostituisce un approccio dialettico, in cui il rapporto fra teorie alternative mira a evidenziare le ipotesi implicite di ognuna e i rispettivi domini di validità, piuttosto che la correttezza di una o dell'altra.

\section{Sull'Economia}
La seconda parte di questo articolo cerca di contestualizzare quanto scritto finora allo stato attuale della disciplina economica, individuando in particolare tre relazioni archetipiche
tra complessità ed economia.
Per farlo, partirò nuovamente da una prospettiva storica.

Verso la fine del XIX secolo, nello stesso periodo in cui nascono i metodi matematici
della complessità, si sviluppa in economia il paradigma marginalista come approccio di ricerca ispirato ai principi riduzionisti. 

Il marginalismo, infatti, cerca di ricondurre lo studio dell'economia alle scelte di ideali agenti economici capaci e volenti di massimizzare dei particolari obiettivi. 
In particolare, il problema tipicamente studiato riguarda trovare le condizioni a cui un piccolo numero di agenti (generalmente uno o due) che davanti alla possibilità di effettuare delle transizioni rinuncino perché nessuna di esse è in grado di migliorare (marginalmente) la situazione di entrambi, condizione nota come ottimo paretiano.

Partendo da quest'idea all'apparenza molto semplice la scuola marginalista sviluppa da una parte dei metodi matematici per studiare questa classe di problemi (generalmente ricorrendo all'analisi matematica sul modello della fisica newtoniana), dall'altra un'intera teoria economica deducendo via via proprietà del sistema sempre più complicate.
La teoria marginalista viene costruita, quindi, per aggiunte successive a un nocciolo elementare di situazioni e assunzioni.

La prima archetipica situazione di un'economia di puro scambio --di baratto-- tra due agenti viene via via generalizzata a una teoria della produzione e, molto successivamente, a una teoria dell'aggregato economico.

Non sarebbe però corretto affermare che i (primi) marginalisti non riconoscessero la natura complessa del sistema economico.
\textcite[p. 20]{marshall1988} nei \textit{Principia} scrive che "La società è qualcosa in più della somma delle vite dei singoli"\footnote{"Society is something more than the sum of the lives of its individual members." (traduzione mia).}, riconoscendo l'economia come un sistema complesso.
Ciononostante, seguendo senza dubbio lo spirito del tempo, il tentativo che viene compiuto è quello di spiegare la complessità come proprietà emergente riconducibile analiticamente a poche leggi fondamentali, così come fatto da Boltzmann con la meccanica statistica.

Dopo una fase di relativo declino nella prima metà del '900, l'approccio marginalista diventa indubbiamente egemone nella disciplina economica a partire dagli anni '70. 

La pervasività dell'operazione egemonica riuscita alla scuola marginalista si può osservare anche --soprattutto-- in come sia mutata la definizione di economia per gli economisti. 
Se può sembrare intuitivo che la disciplina economica studi l'economia, o che venga definita con una concettualizzazione simile a "lo studio dei processi di produzione e scambio", questo non è il contenuto della risposta che darebbero la maggior parte degli economisti.

Nel 1932 Robbins pubblica un libro in cui sostiene che "L'oggetto dell'economia è lo studio dei comportamenti umani nella divisione di risorse scarse"\footnote{"The [...] subject of Economic Science [is the study of] the forms assumed by human behaviour in disposing of scarse means." (traduzione mia)} \parencite[p. 15]{robbins2007}.
L'adozione di questa definizione sposta col tempo l'elemento unificante della disciplina dai contenuti ai metodi, permettendo sia una fase di espansione \textit{imperialista} nello studio dei contenuti tipicamente propri di altre discipline \parencite[cfr.][]{stigler1984, lazear2000} sia di escludere dalle posizioni di potere e prestigio quei filoni di ricerca che non utilizzino gli strumenti utili a studiare l'allocazione ottima di risorse finite ovvero che non formulino la propria domanda di ricerca in termini di ottimizzazione vincolata di una certa funzione obiettivo (chiamata utilità, o seguendo Pareto ofelimità).

Nella pratica l'idea marginalista di costruire una teoria economica sulla base di poche assunzioni riguardo il comportamento umano e le scelte che gli agenti affrontano ha sostituito lo studio dell'economia reale come elemento identitario della disciplina economica.

Il riconoscimento della complessità del reale e la sua riconduzione all'interno del paradigma riduzionistico sono presenti anche in uno degli articoli che hanno fondato la macroeconomia moderna.

Nel 1972 Lucas scrisse che "Dato che la struttura di un modello econometrico si basa sulle regole degli agenti per ottenere una decisione ottimale, e che queste regole variano sistematicamente quando occorrono dei cambiamenti nella struttura delle serie rilevanti per colui che deve prendere la decisione, allora ogni cambiamento nelle politiche altererà sistematicamente la struttura del modello econometrico"\footnote{"Given that the structure of an econometric model consists of optimal decision rules of economic agents, and that optimal decision rules vary systematically with changes in the structure of series relevant to the decision maker, it follows that any change in policy will systematically alter the structure of econometric models." (traduzione mia).} \parencite{lucas1976}.
In altre parole Lucas riconosce che ogni modello quantitativo in economia che si basa su dati reali ha un dominio di validità limitato a quel periodo di tempo in cui permangono le norme socio-culturali --le istituzioni-- per cui è stato immaginato.
Nel fare ciò , inoltre, descrive chiaramente la necessità di riconoscere e descrivere due diversi livelli sulla scala dell'aggregazione (le scelte individuali e il comportamento delle variabili aggregate) e le interazioni fra di essi. Cioè, viene resa esplicita la necessità di integrare microeconomia e macroeconomia.

Volendo rimanere però nel paradigma riduzionista, però, la macroeconomia neoclassica che si sviluppa a partire dalla critica di Lucas si pone il problema di ricondurre le leggi degli aggregati economici alle leggi microeconomiche fondamentali (ovvero di microfondare la ricerca macroeconomica), precludendosi la possibilità di immaginare dei modelli che descrivessero solo il livello aggregato sufficientemente flessibili da accomodare i cambiamenti nelle istituzioni (per esempio recuperando i metodi propri della teoria delle biforcazioni).

Il problema può sembrare a prima vista lo stesso affrontato da Boltzmann un secolo prima e un filone di ricerca noto come Econofisica ha provato per anni, senza risultati risolutivi, ad applicare i metodi della meccanica statistica al problema delle microfondazioni senza successo\footnote{L'elemento mancante in economia per poter tracciare un parallelo utile con la meccanica statistica è la presenza di una quantità che si conservi come l'energia per la fisica. Osservando alcune similitudini questa grandezza dovrebbe avere l'unità di misura di un valore ma nessuna teoria economica riesce a fornire un \textit{principio di conservazione del valore totale} né misurato in termini monetari né misurato in termini di tempo (come valore lavoro).}.
La soluzione perseguita è, almeno fino a tempi recenti, quella di identificare i due livelli, cioè descrivere gli aggregati \textit{come se} fossero singoli agenti. Questa strategia di approssimazione permette di ottenere dei modelli riduzionisti e analiticamente risolvibili, ma genera una serie di paradossi nel momento in cui si cerca di esplorare il nesso tra l'agente rappresentativo (dell'aggregato) e i singoli agenti economici reali \parencite{kirman1992}.

Più o meno contemporaneamente, nel 1987 viene organizzato all'istituto per lo studio dei sistemi complessi di Santa Fe un primo workshop per indagare il possibile ruolo della nascente teoria della complessità nella disciplina economica che vede la partecipazione, tra gli altri, di Anderson, Arrow e Arthur \parencite{fontana2010a}.
\citeauthor{fontana2010a} riporta che "[Arrow] non si aspettava la nascita di un approcio totalmente nuovo: l'impianto teorico generale sarebbe dovuto rimanere invariato, e il ruolo per la `nuova economia', arricchita dalla cooperazioni con fisici e biologi, sarebbe dovuto essere di migliorare lo status quo ante."\footnote{"[Arrow] is not expecting the birth of an entirely new approach: the general framework should remain as it is, with the role for the `new economics', enriched by cooperation with physicists and biologists, being to improve the status quo ante." (traduzione mia)} \parencite{fontana2010a} senza quindi mettere in discussione il metodo deduttivo-riduzionista\footnote{Adottare un approccio deduttivo-riduzionista è fondamentale per molti economisti perché e il metodo delle scienze naturali (e soprattutto della fisica), che permette nella loro visione di elevare l'economia a uno stato di scienza più matura (e in qualche modo migliore in quanto più epistemologicamente solida) delle altre scienze sociali.}.

La direzione del programma per lo studio dell'economia al Santa Fe Institute (SFI) è però assegnata negli anni successivi non ad Arrow ma ad Arthur \parencite{fontana2010a}, che imposta lo sviluppo di un paradigma nuovo che accogliendo l'intuizione di Anderson di porre l'attenzione sulle relazioni tra enti piuttosto che cercare una teoria unificante, si pone come alternativo --eterodosso-- rispetto al paradigma neoclassico (riduzionistico) \parencite{arthur2021, fontana2010}.
Questo filone di ricerca, noto per lo più come Economia della Complessità o Prospettiva di Santa Fe, ha prodotto negli anni numerosi lavori singoli, capaci di indagare temi e impiegare metodi (come le simulazioni computazionali) generalmente trascurati nella disciplina, senza produrre però una teoria unificante per sua stessa natura.

In tempi recenti altri tre fenomeni hanno interessato l'economia influenzando molto il suo rapporto con la complessità.

Il primo è la diffusione dei calcolatori che ha fatto sì che affianco alle soluzioni analitiche si cominciassero ad accettare anche soluzioni ottenute con strumenti computazionali \parencite{cherrier2023, backhouse2016}, per esempio aprendo la strada a modelli macroeconomici che abbandonano in parte l'agente rappresentativo per includere un certo grado di eterogeneità (i modelli HANK).

Il secondo è il progressivo spostamento della disciplina dalla ricerca puramente teorico-modellistica alla ricerca empirica, che basa i risultati su di un'accurata analisi dei dati disponibili \parencite{cherrier2018, backhouse2017}.
Questa svolta neo-empirica è estremizzata da alcuni economisti che rifiutano la necessità di una teoria economica (anche a seguito dei limiti emersi con le crisi dell'inizio del XXI secolo) ritenendo l'analisi dei dati sufficiente a far emergere i rapporti di causa ed effetto sottesi ai fenomeni economici.

Il terzo è la progressiva specializzazione degli economisti che ha portato alla nascita di comunità di ricerca indipendenti tra loro che condividono però un'origine comune nella teoria neoclassica. Questo fenomeno è stato etichettato da alcuni come \textit{mainstream pluralism} \parencite{cedrini2018, davis2006, davis2019a} per sottolineare che esiste una pluralità di programmi di ricerca che convivono tra di loro e convivono con il (e anzi si nutrono del) paradigma dominante --neoclassico-- che li ha preceduti.

Le prossime sessioni saranno destinate a descrivere tre relazioni archetipiche tra complessità ed economia con cui è possibile sia riflettere sullo stato attuale della disciplina economica sia sul ricevimento generale nella scienza dell'idea di complessità.
La prima relazione archetipica è quella che delineava Arrow e che può essere intesa come una delle cause della frammentazione descritta dal \textit{mainstream pluralism}, che definisco post-neoclassica e fa uso degli strumenti matematici della complessità.
La seconda affonda le proprie radici nella svolta neo-empirica e anch'essa fa uso degli strumenti matematici della complessità.
La terza partendo dalla Prospettiva di Santa Fe riesce a fare propria la complessità come meta-teoria.

\subsection{Complessità neo-empirica}
La prima delle tre relazioni archietipiche è quella che possiamo definire neoempirica.
Si inserisce appunto in un filone di ricerca che si muove progressivamente da un approccio
principalmente teorico, un approccio principalmente applicato di creazione di conoscenza
con un'enorme scusione sulla generalizzabilità di questa conoscenza che si potrebbe fare
attraverso la ricerca di relazioni causali di pattern nei dati.
Nella sua versione più semplice, la svolta neoempirica in economia si manifesta con tutta una serie di studi
che si allontanano spesso dai temi classici dell'economia
e che possiamo raggruppare per le scelte tecniche che fanno, per gli strumenti che usano.
Tipicamente evoluzioni del modello di regrezione lineare come gli studi difference in difference,
le procedure di matching, i randomized control trials e i quasi esperimenti,
ovvero un insieme di tecniche che cercano da un insieme di dati che possono essere divisi in due o più gruppi
che differiscono per qualche caratteristica, cercare di recuperare le determinanti di questa caratteristica che distingue i gruppi.
Chiaramente questo tipo di analisi ha innanzitutto un grosso limite, cioè che tende a concentrarsi su differenze al primo ordine
e su problemi che possono in qualche modo essere delineati in un senso di relazione causale,
di confronto fra sottogruppi.
E' velocemente evidente che la possibilità di usare rappresentazioni più complesse o metodi di analisi più complessi
come ad esempio la teoria delle reti o numerosi algoritmi di machine learning permetta in qualche modo di ampliare il tipo di analisi che si può svolgere.
Un esempio architipico è il lavoro di Aidalgo sull'indice di complessità economica,
in cui l'unica assunzione teorica che viene svolta è che l'export di un paese sia il rappresentativo della produzione di quel paese
e che in un approccio puramente empirico basato sull'analisi delle reti di commercio tra i paesi
va a definire un indice di complessità di in qualche modo il livello di avanzamento delle economie mondiali,
lavorando su quella che può sembrare una tutologia, cioè l'assunto è che paesi ad economia avanzata producono beni avanzati
e beni avanzati vengono prodotti in paesi ad economia avanzata.
Questa è tutta la teoria economica che c'è dietro ai lavori di Aidalgo,
che possiamo dire che da un certo punto di vista è geniale, nel senso che con una descrizione tutto sommato semplice,
stilizzata e un buon uso dei dati, riesce a ottenere dei risultati che in qualche modo si allino nell'intuizione.
Ma ci rende estremamente difficile problematizzare che cosa sia un'economia avanzata, perché un'economia avanzata sia tale
e quali siano i contesti istituzionali, i percorsi storici e le relazioni di potere che ci portano a riconoscere come avanzata
un certo tipo di economia e riconoscere quello che ci aspettiamo da un'economia avanzata in certi paesi e non in altri.
Stupidamente manca una prospettiva temporale in questo approccio e impossibile da includere se non forzatamente,
cioè facendo una sequenza di studi in un preciso posto nel tempo, ma senza la possibilità di inserire degli effetti di lungo periodo,
che per esempio impedisce di introdurre una prospettiva colonialista nel discorso.
Dall'altra parte l'uso di metodi statistici sempre più avanzati come il machine learning, come le reti neurali per classificare
o altri strumenti del genere, rende sempre più difficile distinguere il rumore dall'effetto.
I modelli machine learning sono estremamente pronti all'overfitting, ovvero a riconoscere dei pattern anche nel rumore.
E considerando che la qualità dei dati economici è di solito molto bassa e sono generalmente molto rumorosi,
il fatto di muovere verso algoritmi più complessi per cercare di sfuggire da una teoria che appare probabilmente perché è parziale e politica,
rischia di produrre una cattiva scienza, nel senso che ci priva della capacità di leggere quei dati in una maniera che permetta di evidenziare
quali siano gli elementi davvero importanti di quei dati e quali gli elementi trascurabili. Tutto ciò una macchina non può saperlo a priori.
E se i dati sono molto rumorosi è anche difficile inferirlo. Sono cose che noi ricercatori possiamo fare conoscendo il contesto in cui i dati sono presi,
conoscendo il fenomeno che vogliamo studiare e riuscendo a fare una serie di assunzioni teoriche che ci permettono di distinguere
quali sono gli elementi importanti e quindi le scale da tenere in considerazione e quali elementi è probabile che diano correlazioni spurie
o siano solo portatori di rumore perché non c'è motivo concettuale teorico per cui debbano entrare prepotentemente nella relazione che stiamo cercando di studiare.

\subsection{Complessità post-neoclassica}
La seconda relazione è quella che, invece, amo chiamare post-neoclassica e che per tanti
aspetti si avvicina all'idea di mainstream pluralism di Davis et alta.
Il tipo di riflessione che da qui nasce è che la teoria mainstream ha mostrato negli ultimi vent'anni una serie di limiti.
Nel suo essere, probabilmente perché riduzionista, eccessivamente rigida per trattare tutta una serie di situazioni reali che, per qualche motivo, sono diventati maggiori interesse, per esempio la questione ambientale o la fragilità finanziaria.
L'approccio degli studiosi post-neoclassici, che non si riconoscono generalmente come post-neoclassici, è una distinzione che introduco io in questo momento,
non è di rifiutare la teoria cercando rifugio in relazioni empiriche che possano essere estratte da dei dati, facendo un passo indietro e nascondendo le proprie intuizioni teoriche dietro delle procedure standardizzate.
Ma è piuttosto quello di cercare di riflettere su quali assunzioni del proprio modello teorico creano questa rigidità e trovare dei modi tendenzialmente ancora deduttivi di aggirarle.
In questo senso i metodi di matematica e complessità forniscono una serie di strumenti interessanti per, appunto, introdurre delle ipotesi meno restrittive,
ma che rimangano in qualche modo risolvibili, perché portano la formalizzazione del sistema verso una di quelle categorie di sistemi che sono studiate nella teoria della complessità.
Questo tipo di passaggio ha in realtà un esempio storico molto più antico della crisi del mainstream, che è l'adozione in microeconomia della teoria dei giochi.
Nel momento in cui si adotta lo strumento della teoria dei giochi, e particolarmente dei giochi terrati, che sono dei sistemi complessi,
nel senso che, per mantenere il lessico che abbiamo introdotto, introduce una scala di temporalità nell'iterazione del gioco,
è una scala di interazione in cui l'individuo non è più solo, ma interagisce con altro,
e quindi si crea una distinzione tra la descrizione del comportamento dell'individuo e la descrizione della coppia o del gruppo di persone che interagiscono nel gioco.
L'introduzione a teoria dei giochi, in particolare dei giochi iterati, appunto, permette alla microeconomia neoclassica di ampliare il proprio ambito di studi,
riuscendo a alleviare alcune ipotesi, per esempio quella di informazione perfetta, che emerge l'informazione nell'iterazione del gioco.
E quindi diventa poi interessante andare a vedere qual è la convergenza della strategia,
oppure nella simmetria delle funzioni di utilità, permettendo di avere funzioni di utilità simmetriche,
vedendo come queste interagiscono verso un equilibrio piuttosto che un altro.
E quindi questo approccio, in sintesi,
non mira a scartare, come nell'approccio noempirico, o sostituire, come vedremo poi in un'altra prospettiva, la teoria neoclassica.
Ma ha in una modalità riduzionista alla Boltzmann di dotarsi degli strumenti analitici o più recentemente computazionali
che permettano di mantenere il nocciolo teorico di riferimento, l'approccio epistemico di riferimento,
ma definire dei casi particolari in cui alcune ipotesi vengono rilassate,
riconducendo il caso base a un caso particolare della nuova trattazione.
Esempi più recenti possono essere l'introduzione di funzioni di utilità non lineari
in una parte dell'economia comportamentale esperimentale
L'utilizzo di modelli ad agenti computazionali in alcuni ambiti di teoria dell'innovazione,
o in generale di microeconomia, in cui rinunciando alla trattabilità analitica
e accettando una trattabilità computazionale
si possono introdurre assimetrie informative, rigidità
o funzioni di utilità non standard
e osservare l'interazione tra gli agenti quanto e come si discosta
dagli equilibri ipotizzati sotto le ipotesi più restrittive standard.
In maniera meno evidente,
perché non è così chiaro quali sono gli strumenti adottati,
ma diventa evidente se lo guardiamo da un punto di vista delle scale,
rientra senza dubbio in questo filone anche l'economia ambientale.
Che si pone il problema di definire un prezzo per beni non di mercato.
E quindi deve trovare una definizione di prezzo diversa da quella standard
che si applichi anche a una definizione di prezzo diversa da quella standard
che si applichi anche a beni di per sé non di mercato.

\subsection{Complessità meta-teorica}
La terza relazione archietipica è quella che utilizza la complessità come metatheoria
e si sviluppa a partire dai lavori di Brian Arthur e il resto del gruppo a Santa Fe, spesso chiamata economia della complessità.
Questo terzo archietipo è anche il più difficile a descrivere perché non ha lasciato dietro
di sé un gran numero di lavori o una scuola ben definita, in parte per le sue naturali
caratteristiche, in parte perché il modo di fare ricerca seguendo l'idea di una complessità
come metatheoria si sposa male con le norme sociali dell'accademia contemporanea,
in particolare dell'economia. Forse mettere una nota sul grado di gerarchizzazione della disciplina.
Questo perché i lavori sviluppati in questo campo sono per lo più autoconsistenti,
nel senso che partono da una domanda di ricerca, lavorano per sviluppare generalmente un modello
che risponde a questa domanda e poi finiscono lì, senza generare un flusso continuo di pubblicazioni
su argomenti simili. Questo credo che sia abbastanza conseguenza di un approccio olistico
piuttosto che un approccio riduzionistico. Questo perché se noi partiamo da dimensione
olistica della disciplina, l'approccio sarà quello di partire dal tutto, la realtà,
il mondo o qualche altra forma di totale, e poi procedere per sottrazione eliminando
quelle scale e quei livelli sulle scale per cui il nostro fenomeno di interesse,
il fenomeno che risponde alla nostra domanda di ricerca, non si manifesta o si manifesta
in maniera costante e quindi risultano non di interesse. Questo fa sì però che cambiando
la domanda di ricerca, questo processo di analisi e di approssimazioni successive debba
essere ripetuto, ogni volta per ogni nuova domanda di ricerca, portando potenzialmente
a scartare delle scale o a spostarsi su dei livelli che non erano stati prese in considerazione
prima. Come conseguenze di ciò, le ipotesi di lavoro tendono a essere diverse studio
per studio, al contrario di un approccio riduzionista in cui le ipotesi di lavoro sono
le stesse, il punto di partenza è lo stesso e quindi in qualche modo il processo di approssimazioni
successive non è ripetuto ogni studio ma è svolto una volta all'inizio del fenomeno
di ricerca e poi più o meno non ripetuto, a cui poi a questo corpo di ipotesi di lavoro
vengono fatte delle piccole aggiunte, delle piccole modifiche, in questo senso si mantiene
comunque un discorso di approssimazioni successive che permettano di rispondere a nuova domanda
di ricerca in una maniera leggermente diversa rispetto alla vecchia domanda di ricerca.
Viene da sé che questo approccio ha due grossi limiti. Il primo è quello di introdurre una
fase di ricerca assente nell'approccio classico riduzionistico che è quella dell'adeguamento
e della ridefinizione delle ipotesi di lavoro in base alla specifica domanda di ricerca,
allungando quindi tempi per la produzione di prodotti della ricerca e quindi di materiale
rendi contabile nelle procedure amministrative di carriera proprie dell'accademia neoliberale.
Dall'altra parte rende più difficile inserirsi in un filone di letteratura che ti riconosca
come parte organica di esso e che quindi ti permetta di entrare in un naturale gruppo di
autori che tra di loro si citano perché riconoscono lavori affini, lavori simili nel senso di variazioni
sul tema di uno stesso nocciolo iniziale da cui poter attingere dettagli, idee, soluzioni
senza però mettere in discussione tutto l'approccio ed entrando in un gruppo di ricercatori che
si identificano si entra in un gruppo di ricercatori che si citano migliorando le metriche che vengono
utilizzate per i processi valutativi dell'accademia neoliberale. In sintesi quindi
questo terzo archetipo non è riconoscibile sulla base di un particolare uso degli studenti
matematici della complessità o di particolare ipotesi di lavoro ma da un certo modo di fare
scienza, da un certo modo di costruire le ipotesi di lavoro con cui lo studio viene poi eseguito.
Altro dettaglio che rende in parte più difficile creare un'identità e che spiega dall'altra parte
molto bene in che senso la teoria della complessità in senso metateorico non è di per sé una teoria
perché non produce un corpo coerente, almeno non in prima battuta, di metodi pratiche,
conoscenze e ipotesi condivise, ma esplica un metodo di lavoro.
Un metodo di lavoro che si pone in relazione essenzialmente dialettica e inclusiva rispetto
alla teoria già sviluppata da precedenti teorie. La necessità per un approccio complesso
di rifiutare la teoria neoclassica dominante non è strettamente sulla scelta delle ipotesi,
ma sull'assolutizzazione delle ipotesi, sul non riconoscere, cioè che le ipotesi di lavoro
della teoria neoclassica non sono assolute e valide per la descrizione di qualunque fenomeno
economico, ma che debbano e possano essere usate solo per quelle domande di ricerca che,
al termine del processo di analisi e approssimazioni successive,
delinino un fenomeno da studiare che sia coerente con le ipotesi neoclassiche.
Si può pensare, per esempio, che alcuni mercati finanziari o mercati costellati da
un certo numero di grandi aziende rispecchino in fin dei conti le assunzioni neoclassiche di
un livello di conoscenza magari non perfetta ma comune fra i vari agenti, un comportamento
ottimizzante dei vari agenti, la presenza di variabile continua nel determinare i comportamenti
dei vari agenti e che quindi la descrizione neoclassica dell'oligopolio o del mercato o
del monopolio possa per questo tipo di aziende essere una buona descrizione per alcuni comportamenti
di queste aziende, ma non perché le ipotesi neoclassiche siano a priori corrette, ma perché
nell'analizzare il fenomeno riconosciamo che le approssimazioni che portano alle ipotesi
neoclassiche sono, per la sensibilità dello studioso, coerenti con il fenomeno oggetto di studi.
E anche in questo senso, come scrivevo prima, non ritengo corretto vedere l'approccio metateorico
alla complessità come qualcosa di pluralistico, nel senso che nel pluralismo l'idea è che
differenti teorie competano o che esistino differenti teorie, mentre il punto di vista
che cerco di portare è che queste teorie, queste che oggi chiamiamo teorie, sono in
realtà aspetti complementari di un'osservazione unificata, che non dobbiamo contrapporre
una teoria poschinesiana e una teoria neochinesiana, dobbiamo riconoscere quali sono le ipotesi
di lavoro sottostanti a queste due teorie e quindi essere in grado di riconoscere che
una teoria economica ampia sia in grado di attingere da entrambe queste tradizioni,
da entrambe queste fonti di conoscenza a seconda dello specifico fenomeno di interesse.
Questa cosa la metto un po' così, forse andrà in nota, forse nel testo.
Va la pena notare che Marc Labois, un importante esponente della scuola poschinesiana contemporanea,
nel suo libro di testo descrive le caratteristiche che un'etero-dossia e in particolare scrive
l'etero-dossia poschinesiana dovrebbe avere. Fra queste ci sono l'olismo, il realismo,
la necessità di dialogare con altre discipline, altre scuole per superare i propri limiti.
Mi sembra interessante evidenziare questo perché già si potrebbe discutere che il
noccio di assunzioni fondamentali dell'economia poschinesiana sia tutto sommato limitato essendo
questa bene o male un contenitore al suo interno piuttosto eterogeneo.
Dall'altra parte sembra accennare una possibile convergenza,
fra quanto discusso in questo paper e le pratiche di ricerca con la comunità.
E' sicuramente un discorso da approfondire maggiormente, soprattutto nel cercare di
individuare quale siano effettivamente le ipotesi in uso da parte di alcuni o tutti
i tipi poschinesiani, che siano assunte come ipotesi di lavoro standard non giustificate
da un processo di analisi e di approssimazione della realtà in base agli argomenti di studio
tipici affrontati dalla scuola.

\section{Sulla realtà}
I want to empathize that a sincerely complex approach puts at leat as much emphasis on the processes than on the results, if not more. How a research question is chosen and how a model is tailored (and so the reasoning behind it) are a fundamental part of how research is doing and should be communicated and valorized on its own, where results remain a useful appendix of doing science.

È lecito chiedersi quanto sia realistico il programma di ricerca che sto proponendo,
il metodo di ricerca che sto proponendo.
Dividerei questa riflessione sul realismo in due parti.
Una prima scevra da norme sociali e limiti amministrativi e una seconda invece calata
nel contesto contemporaneo di aziendalizzazione dell'università.
Di per sé non è un programma di ricerca che fondamentalmente mini l'attuale modo
di far ricerca.
Ricchiede da parte del ricercatore una maggiore consapevolezza, soprattutto gli studi iniziali
della ricerca, per poter riconoscere quali sono le ipotesi di lavoro che sta effettivamente
utilizzando, al fine di poter discutere criticamente la loro relazione con l'oggetto di studi,
con i fenomeni che si stanno studiando.
Non mi è difficile immaginare che un approccio del genere possa portarci a dover sviluppare
un'effettiva rivoluzione epistemica, perché il processo di approssimazione è almeno
in parte legato alla sensibilità del ricercatore e quindi si introduce una dimensione suggestiva
non tanto nel processo deduttivo in sé che ci porta a definire le ipotesi di lavoro,
ma nella scelta, nella possibilità di prendere per vere certe approssimazioni, anche solo
perché necessariamente un primo studio che voglia arrivare a definire delle proprietà
di carattere generale dovrà tenere conto solo delle cause o delle relazioni maggiormente
significative e quindi approssimando quelle che potremmo chiamare relazioni o correlazioni
fenomeni di secondo ordine e distinguere cosa sia una approssimazione, cosa sia una relazione
di primo o di secondo ordine, che quindi possa lecitamente essere approssimata in una prima
battuta o meno, non è semplicissimo da definire, perché spesso anche approcci sperimentali
che cerchino di definire l'intensità delle relazioni causali si basano su tutto un apparato
teorico che a sua volta soffre del problema di dover decidere che cosa è fondamentale e cosa
no e che quasi sempre fa uso di proxy nel momento in cui vengono svolte le misure,
quindi introducendo un grado di arbitrarietà ed imprecisione al sistema che potenzialmente
può vanificare il tentativo di misura. Non penso che una tale rivoluzione epistemica
che riconosca essenzialmente la soggettività del ricercatore, quindi la contestualità dei risultati
della ricerca, sia a priori da rifiutare in quanto irrealistica, anche perché seguendo un approccio
di complessità con metatheoria, il ricercatore esplicita quanto più possibile il contesto,
le proprie ipotesi e quindi in qualche modo diventa chiaro quali sono le premesse da cui
il risultato della ricerca segue, rendendo anche facile confutare o comunque ricondurre al corretto
ambito di applicazione pratica il risultato ottenuto. Dall'altra parte, potrebbe verosimilmente
portare a un rallentamento dell'attività di ricerca, un'attività di ricerca più curata
e più distante da dei principi di catena di montaggio e di produzione continua,
auspicio che però è comune in tante riflessioni sul futuro dell'università. Credo anche però che
questa roba sia meno vera nella pratica di quanto possa sembrare la teoria, nel senso che ci sono
domande di ricerca che nella prima forma o in variazioni che richiedono sì di rivedere ma non
di rimettere totalmente in discussione le ipotesi di lavoro, possono coprire l'intera carriera
accademica di un ricercatore o di un gruppo di ricerca, quindi con la sensibilità di periodicamente
verificare che il lavoro di ricerca non si sia distanziato troppo dalle proprie ipotesi di lavoro.
È anche facile che per alcuni ricercatori il processo di analisi, ovvero di definizione dell'oggetto
di ricerca, delle scale, dei livelli su di essi interessanti e quindi delle relative
approssimazioni e di ipotesi di lavoro conseguenti sia un lavoro che factualmente possa essere fatto
un numero limitato di volte nella vita accademica di un ricercatore a meno di ricercatori che non
come realtà poi è quello che possiamo per lo più osservare negli sviluppi dell'economia
della complessità degli ultimi anni segnare sul terzo archetipo che si chiama economia della
complessità. Ricercatori che cambino frequentemente metodi, temi, argomenti di ricerca e quindi
ripetendo questo processo di definizione della cornice di ricerca più volte nel corso della
propria carriera. Sicuramente più reali sono i limiti che l'aziendalizzazione dell'accademia
C'è da dire che essi non sono limiti intrinsechi alla produzione di conoscenza, ma norme sociali
e in ultima analisi scelte politiche della comunità in senso ampio in cui ricercatori vivono.
In questo senso abbiamo già evidenziato che due punti, che è un approccio di complessità metà
teorica solleva, che sono difficilmente conciliabili con le norme sociali e valutative in atto,
sono appunto la velocità di produzione della ricerca, per cui un approccio riduzionista
da aggiungere di variazioni sul tema e in grado di garantire una produzione maggiore di prodotti
della ricerca rispetto a un lavoro analitico a sottrarre come quello che sto proponendo.
E dall'altra parte l'indubbio vantaggio a livello di valutazione del proprio operato che hanno i
ricercatori che partecipano in comunità di ricerca grosse, con una forte identità e che
producono lavori che possano essere riconosciuti simili da altri ricercatori.
E questa necessità di accumulare citazioni, quindi riconoscimento, all'interno di una
specifica nicchia, quanto più grande meglio è della disciplina, che fa sì che tutta una serie
di ipotesi di lavoro siano necessarie da assumere per garantirsi un proseguimento di carriera,
e non possono essere di fatto scartate nemmeno se in qualche modo ostacolano lo studio del
fenomeno in oggetto, perché porterebbero il prodotto della ricerca e il lavoro del ricercatore
a distanziarsi da una comunità e quindi a distanziarsi da coloro che possono riconoscere
questo articolo non solo come valido e interessante, ma come rilevante per il loro lavoro e quindi
citarlo e quindi di fatto ritribuire il lavoro dell'autore garantendo una rendita che poi si
realizza generalmente nell'ottenimento di promozioni, di maggiori fondi o della possibilità
di allargare il proprio gruppo di ricerca. E questa intrinse camofilia nell'accademia contemporanea
è probabilmente ciò che ci impedisce di saltare gli steccati disciplinari a livello metodologico
o di conoscenza accumulata e cui attingere, di muoverci negli interstizi tra differenti tradizioni
di studio dell'economia e quindi superando una visione di pluralismo in cui ogni tradizione
deve essere opposta e mirare a superare l'altra invece che contestualizzata in ciò che si è
dimostrata capace di studiare. E alla fine è un comportamento assimilante per cui piuttosto
che mettere in discussione le pratiche di ricerca per provare a studiare in maniera più appropriata
un fenomeno nuovo si preferisce studiare un po' peggio ma con la garanzia di essere riconosciuti
parte di una comunità. In altre parole non credo ci siano limiti epistemici o di effettivo svolgimento
del lavoro di ricerca all'assumere un approccio complesso in senso metateorico in economia o in qualunque
altra disciplina. Credo però che le attuali condizioni sociali e di riproduzione dell'accademia
che vengano in maniera essenziale la possibilità di utilizzare tale approccio che non fa altro che
mettere a fuoco da una parte l'esplicitazione di dei processi impliciti che vengono già fatti
nel momento in cui si assumono certe ipotesi di lavoro piuttosto che altre spesso senza giustificarle
rispetto al preciso oggetto di studi. E dall'altra un'intuizione che mi sembra banale
che quella di dover piegare il proprio approccio e le proprie premesse all'oggetto di studi
e non l'oggetto di studi a un approccio a una premessa decisa a priori.

stilemi, globalizzazionbe della ricerca

\begin{refcontext}[sorting=nyt]
	\printbibliography
\end{refcontext}

\end{document}